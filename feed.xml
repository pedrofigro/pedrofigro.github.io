<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://pedrofigro.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://pedrofigro.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-05T06:38:50+00:00</updated><id>https://pedrofigro.github.io/feed.xml</id><title type="html">blank</title><subtitle>The website of Dr. Pedro Figueroa-Romero </subtitle><entry><title type="html">Uncertainties in RB</title><link href="https://pedrofigro.github.io/blog/2025/rbuncertainty/" rel="alternate" type="text/html" title="Uncertainties in RB"/><published>2025-12-02T07:55:00+00:00</published><updated>2025-12-02T07:55:00+00:00</updated><id>https://pedrofigro.github.io/blog/2025/rbuncertainty</id><content type="html" xml:base="https://pedrofigro.github.io/blog/2025/rbuncertainty/"><![CDATA[<h1 id="uncertainties-in-rb">Uncertainties in RB</h1> <p>During my BSc in Physics (<em>Licenciatura en F√≠sica</em>), I was always frustrated by the experimental courses‚Äînot because of the experiments themselves, but because of the analysis afterwards. Worst of all was dealing with statistics and numerical uncertainties! Ironically, those very tools later became central to my career.</p> <p>Fast forward to the end of my PhD: I entered the quantum computing world through the technique now widely known as <a href="https://en.wikipedia.org/wiki/Randomized_benchmarking">Randomised Benchmarking</a>, or simply RB. Within the quantum computing community‚Äîhardware engineers and theorists alike‚ÄîRB is regarded as <em>the</em> standard method for estimating gate fidelities. Of course, there are other approaches, but RB remains the primary tool for this purpose.</p> <p>For those of us working more deeply in the <a href="https://arxiv.org/abs/2503.16383">QCVV</a> sub-field, RB is better understood as a broad framework that has spawned numerous variants and related techniques. The boundaries between them are often blurry. For example, the <em>traditional</em> single-qubit and two-qubit Clifford RB can be seen as a special case of the <a href="https://www.nature.com/articles/s41467-023-39382-9">Gate Set Shadow framework</a>. Historically, RB also helped popularise the concept of <a href="https://en.wikipedia.org/wiki/Quantum_t-design">unitary <em>t</em>-designs</a>‚Äîensembles of gates that mimic the uniform distribution over the unitary group up to the <em>t</em><sup>th</sup> statistical moment. This unitary design concept is now essential for many randomised protocols to be practical.</p> <p>Within the broader community, however, RB is often associated with some <em>folk claims</em>. Two common ones are:</p> <ul> <li>RB always produces an exponential decay from which fidelity can be extracted.</li> <li>The Clifford group is always a 2-design.</li> </ul> <p>Both claims are conditional. The first depends on whether the average noise <a href="https://arxiv.org/abs/1109.6887">approximately satisfies certain assumptions</a>. The second depends on the <a href="https://arxiv.org/abs/2108.04200">dimensionality of the group</a>.</p> <hr/> <h2 id="reading-between-the-lines-of-rb-data">Reading between the lines of RB Data</h2> <p>Beyond these headline results, RB outputs contain subtler information about the average noise.</p> <ul> <li><strong>Exponential decay of the averages:</strong> If the average survival probabilities at chosen sequence lengths do not follow an exponential decay, one should proceed with caution. Questions arise: <em>How many outliers are there? Are enough sequence lengths sampled? Should more circuits be run? Is there a quantitative measure of the deviations?</em></li> <li><strong>Distribution of survival probabilities:</strong> Even when averages fit an exponential decay, the distribution of individual survival probabilities at fixed sequence lengths can reveal the nature of the noise. Error bars (often the <a href="https://en.wikipedia.org/wiki/Standard_error">standard error</a> of the mean) are useful, but they may conceal skewness or outliers.</li> </ul> <p>The key point is that <em>minimally processed data</em>‚Äîindividual survival probabilities‚Äîcan already indicate whether something could be more seriously wrong (non-exponential behavior, skewed distributions, big outliers). Moreover, the variance of these probabilities at each sequence length is related to the purity of the outputs, which in turn provides qualitative insight into the <a href="https://arxiv.org/abs/1503.07865"><em>unitarity</em></a>‚Äîa measure of how unitary the noise channel is.</p> <p>This matters because it affects how much confidence one can place in the reported fidelity. Importantly, I‚Äôm not referring to the uncertainty in the final fitted number (which depends on the fitting procedure and its assumptions). Rather, I mean the uncertainty inherent in each average point at every chosen sequence length.</p> <hr/> <h2 id="examples-urb-and-iirb">Examples: URB and IIRB</h2> <p>Two protocols illustrate these ideas clearly: <em>Unitarity RB (URB)</em> and <em>Iterative Interleaved RB (IIRB).</em></p> <h3 id="urb">URB</h3> <p>URB estimates how unitary the noise is, with a fidelity-like measure, on average. It modifies standard Clifford RB by requiring measurements in all Pauli bases (effectively tomography for each circuit sample). Introduced in <a href="https://arxiv.org/abs/1503.07865">arXiv:1503.07865</a>, URB also formalised the definition of <em>unitarity</em>. In our own work (<a href="arXiv:2409.02110">arXiv:2409.02110</a>), we extended URB and derived an upper bound for the unitarity of Pauli noise in terms of fidelity. Depolarizing noise achieves the lowest possible unitarity, while purely unitary channels have unitarity 1 - we <em>bridged</em> that gap so that you can tell whether the unitarity is close to that of purely stochastic noise (between upper-bound and depolarizing) or it certainly has a coherent contribution (between upper-bound and 1).</p> <p>Running Clifford RB alongside URB highlights differences: two noise models with the same fidelity‚Äîone dominated by stochastic errors, the other by coherent errors‚Äîproduce starkly different decays. The coherent case exhibits higher unitarity.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/purity_stoch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/purity_coherent.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="iirb">IIRB</h3> <p>IIRB tweaks Interleaved RB by interleaving the gate of interest multiple times and examining the estimated fidelities. First proposed in <a href="https://arxiv.org/abs/1504.06597">arXiv:1504.06597</a>, it was later used in <a href="https://arxiv.org/abs/2508.16437">IQM‚Äôs demonstration</a> of native two-qubit gates with fidelities above 99.9%.</p> <p>The principle is simple: fidelity should decay linearly with the number of interleavings, equal to the slope of decay. If it decays faster, errors are accumulating more severely than expected under stochastic noise. Simulation with models as above for URB show a clear difference between stochastic and coherent noise.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/iirb_stochastic.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/iirb_coherent.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/iirb_slopes.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <hr/> <h2 id="why-coherence-matters">Why coherence matters</h2> <p>Ironically, when survival probability distributions are presented at several sequence lengths, they often resemble the coherent case. This is significant because coherence in noise impacts:</p> <ol> <li><strong>Fault-tolerance thresholds</strong></li> <li><strong>Error accumulation over time</strong></li> </ol> <p>For deeper discussion on these, see <a href="https://arxiv.org/abs/2207.08786">arXiv:2207.08786</a> and this <a href="https://www.youtube.com/live/0TxQF1VuBqY?si=O9x4IfECtzNEvNkW">Qiskit seminar</a>.</p> <p>Ironically enough, when people actually present the distribution of survival probabilities in the decays, often they look more like the coherent case. I often try to emphasise that reported fidelity is <em>not a good quality metric</em>, or not a sufficient one, at least in this sense, since I often get the impression of ‚Äúfidelity‚Äù being another folk term within the community. To be fair, it is a really good figure of merit in the sense that it is the quality metric that we can estimate, at least approximately and with relative ease üòÖ</p>]]></content><author><name></name></author><category term="benchmarking"/><category term="randomised"/><category term="benchmarking"/><summary type="html"><![CDATA[Cause if you like it, then you shoulda put uncertainties on it]]></summary></entry></feed>